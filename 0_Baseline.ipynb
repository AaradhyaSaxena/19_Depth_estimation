{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels : 8000\n"
     ]
    }
   ],
   "source": [
    "# Training label\n",
    "\n",
    "a = open('data/train_label.pkl', 'rb')   \n",
    "label = pickle.load(a) \n",
    "a.close\n",
    "print(\"Number of labels :\",len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of image : 8000\n",
      "length of image[0] : 784\n"
     ]
    }
   ],
   "source": [
    "# Training images\n",
    "\n",
    "img = open('data/train_image.pkl', 'rb')   \n",
    "image = pickle.load(img) \n",
    "img.close\n",
    "print(\"length of image :\",len(image))\n",
    "# print(image[0])\n",
    "print(\"length of image[0] :\",len(image[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of image : 2000\n",
      "length of image[0] : 784\n"
     ]
    }
   ],
   "source": [
    "# Testing Data\n",
    "img1 = open('data/test_image.pkl', 'rb')   \n",
    "test_im = pickle.load(img1) \n",
    "img1.close\n",
    "print(\"length of image :\",len(test_im))\n",
    "# print(image[0])\n",
    "print(\"length of image[0] :\",len(test_im[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 3, 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_im = np.array(image, dtype='float32')\n",
    "test_im = np.array(test_im, dtype='float32')\n",
    "\n",
    "X_train = train_im / 255\n",
    "Y_train = np.array(label ,dtype = 'uint8')\n",
    "\n",
    "X_test = test_im / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2000):\n",
    "    Y_train[i] = 0\n",
    "for i in range(2000,4000):\n",
    "    Y_train[i] = 1\n",
    "for i in range(4000,6000):\n",
    "    Y_train[i] = 2\n",
    "for i in range(6000,8000):\n",
    "    Y_train[i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "encoded = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into train and validate arrays \n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(\n",
    "    X_train, encoded, test_size = 0.2, random_state= 2145,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets see what the images look like\n",
    "image1 = x_train[5000, :].reshape((28, 28))\n",
    "\n",
    "plt.imshow(image1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (6400, 28, 28, 1)\n",
      "x_test shape: (2000, 28, 28, 1)\n",
      "x_validate shape: (1600, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "im_rows = 28\n",
    "im_cols = 28\n",
    "batch_size = 512\n",
    "im_shape = (im_rows, im_cols, 1)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
    "x_test = X_test.reshape(X_test.shape[0], *im_shape)\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *im_shape)\n",
    "\n",
    "print('x_train shape: {}'.format(x_train.shape))\n",
    "print('x_test shape: {}'.format(x_test.shape))\n",
    "print('x_validate shape: {}'.format(x_validate.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=im_shape),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),   #relu\n",
    "    Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard = TensorBoard(\n",
    "#     log_dir=r'logs\\{}'.format('cnn_1layer'),\n",
    "#     write_graph=True,\n",
    "#     write_grads=True,\n",
    "#     #histogram_freq=1,\n",
    "#     write_images=True,\n",
    "# )\n",
    "\n",
    "cnn_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# model.compile(optimizer='adam', \n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 13s 2ms/step - loss: 1.0172 - acc: 0.5950 - val_loss: 0.6940 - val_acc: 0.7081\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 1s 137us/step - loss: 0.6568 - acc: 0.7258 - val_loss: 0.6151 - val_acc: 0.7406\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 1s 144us/step - loss: 0.5833 - acc: 0.7661 - val_loss: 0.5635 - val_acc: 0.7750\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 1s 157us/step - loss: 0.5281 - acc: 0.8033 - val_loss: 0.5182 - val_acc: 0.7963\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 1s 151us/step - loss: 0.4945 - acc: 0.8131 - val_loss: 0.4878 - val_acc: 0.8075\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 1s 140us/step - loss: 0.4731 - acc: 0.8225 - val_loss: 0.4972 - val_acc: 0.8063\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 1s 139us/step - loss: 0.4575 - acc: 0.8261 - val_loss: 0.4651 - val_acc: 0.8169\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 1s 137us/step - loss: 0.4285 - acc: 0.8417 - val_loss: 0.4655 - val_acc: 0.8113\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 1s 145us/step - loss: 0.4187 - acc: 0.8417 - val_loss: 0.4369 - val_acc: 0.8256\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 1s 136us/step - loss: 0.4044 - acc: 0.8486 - val_loss: 0.4442 - val_acc: 0.8306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26af07d7978>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(\n",
    "    x_train, y_train, batch_size=batch_size,\n",
    "    epochs=10, verbose=1,\n",
    "    validation_data=(x_validate, y_validate),\n",
    "    #callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3925\n",
      "training acc: 0.8580\n"
     ]
    }
   ],
   "source": [
    "score = cnn_model.evaluate(x_train, y_train, verbose=0)\n",
    "\n",
    "print('training loss: {:.4f}'.format(score[0]))\n",
    "print('training acc: {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = cnn_model.predict_classes(x_test)\n",
    "\n",
    "y\n",
    "# # show the inputs and predicted outputs\n",
    "# for i in range(len(x_train)):\n",
    "#     print(\"X=%s, Predicted=%s\" % (x_train[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2000):\n",
    "    if(y[i] = 1):\n",
    "        y[i] = 2\n",
    "    else if(y[i] = 2):\n",
    "        y[i] = 3\n",
    "    else if(y[i] = 3):\n",
    "        y[i] = 6\n",
    "    else:\n",
    "        y[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(len(x_test))\n",
    "columns = ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y, index= index, columns = columns)\n",
    "df.head()\n",
    "\n",
    "df.to_csv(\"cv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######################\n",
    "\n",
    "\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "##############################################\n",
    "\n",
    "\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "#######################\n",
    "#######################\n",
    "\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
